{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install speechrecognition langdetect"
      ],
      "metadata": {
        "id": "KSJuH5gc4MP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m12eRZwh4C-Q",
        "outputId": "52f7c288-0363-41fa-ac79-2c7e4f59baef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /tmp/tmp56t5vq8c.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "_____________________________________________________________________\n",
            "\n",
            "Psychometric Analysis To Given Video:\n",
            "\n",
            "Video to Text Convert successfully:\n",
            "Text: hello my name is Patricia Espiritu I am 24 years old from the Philippines I have a bachelor's degree in Business Administration major in financial management and I have a tissue and tefl certification I am a bank employee for almost 4 years now where I was at customer service for 2 years I love teaching kids and I'm very excited to make a great impact in your company\n",
            "Grammar Score: 70.27/100\n",
            "Facial Expression: Good\n",
            "Facial Expression Rating: 6.6/10\n",
            "Detected Language: en\n",
            "Gender Prediction: Female\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import moviepy.editor as mp\n",
        "import librosa\n",
        "import speech_recognition as sr\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from textblob import TextBlob\n",
        "from langdetect import detect, detect_langs\n",
        "import tempfile\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to convert video to text using moviepy\n",
        "def video_to_text(video_path):\n",
        "    try:\n",
        "        video_clip = mp.VideoFileClip(video_path)\n",
        "        audio_clip = video_clip.audio\n",
        "        temp_audio_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
        "        temp_audio_path = temp_audio_file.name\n",
        "        temp_audio_file.close()\n",
        "\n",
        "        audio_clip.write_audiofile(temp_audio_path)\n",
        "\n",
        "        recognizer = sr.Recognizer()\n",
        "        with sr.AudioFile(temp_audio_path) as source:\n",
        "            audio_text = recognizer.record(source)\n",
        "\n",
        "        transcribed_text = recognizer.recognize_google(audio_text)\n",
        "        return transcribed_text, temp_audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in video_to_text: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    words = [word.lower() for word in words]\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return words\n",
        "\n",
        "# Function to calculate grammar score\n",
        "def calculate_grammar_score(text):\n",
        "    words = preprocess_text(text)\n",
        "    pos_tags = pos_tag(words)\n",
        "    noun_count = sum(1 for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('PRP'))\n",
        "    verb_count = sum(1 for word, pos in pos_tags if pos.startswith('VB'))\n",
        "    total_words = len(words)\n",
        "    if total_words == 0:\n",
        "        return 0\n",
        "    return ((noun_count + verb_count) / total_words) * 100\n",
        "\n",
        "# Function to extract MFCC features from an audio file\n",
        "def extract_features(audio_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=None)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        return np.mean(mfccs.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in extract_features: {e}\")\n",
        "        return None\n",
        "\n",
        "# Ensure at least two samples per class\n",
        "def check_class_distribution(labels):\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    class_distribution = dict(zip(unique, counts))\n",
        "    if any(count < 2 for count in counts):\n",
        "        raise ValueError(\"Each class must have at least 2 samples.\")\n",
        "    return class_distribution\n",
        "\n",
        "# Function to recognize speech from audio file\n",
        "def recognize_speech_from_audio(audio_file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file_path) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        return recognizer.recognize_google(audio)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Speech Recognition could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in recognize_speech_from_audio: {e}\")\n",
        "    return None\n",
        "\n",
        "# Function to detect language of the text\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        language = detect(text)\n",
        "        return language\n",
        "    except Exception as e:\n",
        "        print(f\"Error in detecting language: {e}\")\n",
        "    return None, None\n",
        "\n",
        "# Function to analyze sentiment using TextBlob\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    if sentiment_score > 0:\n",
        "        return \"Good\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"Bad\"\n",
        "    else:\n",
        "        return \"Average\"\n",
        "\n",
        "# Function to map sentiment score to a rating out of 10\n",
        "def analyze_sentiment_rating(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    return (sentiment_score + 1) * 5  # Map [-1, 1] to [1, 10]\n",
        "\n",
        "def gender_predict(temp_audio_path):\n",
        " # Example audio gender prediction\n",
        "        audio_files = [\n",
        "            'male-audio.wav',\n",
        "            'male-audio1.wav',\n",
        "            'female-audio.wav',\n",
        "            'female-audio1.wav'\n",
        "        ]\n",
        "        labels = [\n",
        "            0,  # Male\n",
        "            0,  # Male\n",
        "            1,  # Female\n",
        "            1   # Female\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            check_class_distribution(labels)\n",
        "\n",
        "            features = np.array([extract_features(file) for file in audio_files])\n",
        "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=42, stratify=labels)\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            classifier = SVC(kernel='linear', probability=True)\n",
        "            classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "            own_features = extract_features(temp_audio_path)\n",
        "            if own_features is not None:\n",
        "                own_features_scaled = scaler.transform([own_features])\n",
        "                predicted_gender = classifier.predict(own_features_scaled)\n",
        "                return('Female' if predicted_gender[0] == 1 else 'Male')\n",
        "            else:\n",
        "                print(\"Failed to extract features from the audio file for gender prediction.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in audio gender prediction: {e}\")\n",
        "\n",
        "        # Clean up the temporary audio file\n",
        "        if os.path.exists(temp_audio_path):\n",
        "            os.remove(temp_audio_path)\n",
        "\n",
        "\n",
        "# Main function to integrate functionalities\n",
        "def main(video_path):\n",
        "    # Example video to text conversion\n",
        "    video_text, temp_audio_path = video_to_text(video_path)\n",
        "    if video_text:\n",
        "        print(\"_____________________________________________________________________\")\n",
        "        print(\"\\nPsychometric Analysis To Given Video:\")\n",
        "        print(\"\\nVideo to Text Convert successfully:\")\n",
        "        print(\"Text:\", video_text)\n",
        "\n",
        "        # Example grammar score calculation\n",
        "        grammar_score = calculate_grammar_score(video_text)\n",
        "        print(f\"Grammar Score: {grammar_score:.2f}/100\")\n",
        "\n",
        "        # Example sentiment analysis\n",
        "        sentiment = analyze_sentiment(video_text)\n",
        "        sentiment_rating = analyze_sentiment_rating(video_text)\n",
        "        print(\"Facial Expression:\", sentiment)\n",
        "        print(f\"Facial Expression Rating: {sentiment_rating:.1f}/10\")\n",
        "\n",
        "        # Example language detection\n",
        "        detected_language = detect_language(video_text)\n",
        "        print(\"Detected Language:\", detected_language)\n",
        "\n",
        "        # Gender prediction\n",
        "        gender_prediction = gender_predict(temp_audio_path)\n",
        "        print(\"Gender Prediction:\",gender_prediction)\n",
        "\n",
        "\n",
        "video_path = \"project-video.mp4\"\n",
        "main(video_path)"
      ]
    }
  ]
}